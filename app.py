from pathlib import Path
import PIL
import pyttsx3
import cv2
import streamlit as st
import settings
import helper

# ‚úÖ Set Streamlit page config
st.set_page_config(
    page_title="Sign Language Recognition using YOLOv8",
    page_icon="üßè‚Äç‚ôÄÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ‚úÖ Page title
st.title("ü§ñ Sign Language Recognition using YOLOv8")

# ‚úÖ Sidebar - Confidence slider
confidence = float(st.sidebar.slider("Select Model Confidence", 25, 100, 40)) / 100

# ‚úÖ Load model
model_path = Path(settings.DETECTION_MODEL)
try:
    model = helper.load_model(model_path)
except Exception as ex:
    st.error(f"‚ö†Ô∏è Unable to load model. Check the path: `{model_path}`")
    st.exception(ex)
    st.stop()

# ‚úÖ Text-to-speech for detected letter
def speak_detected_letter():
    try:
        engine = pyttsx3.init()
        engine.setProperty('rate', 150)
        letter = st.session_state.get("last_detected_letter", None)
        if letter:
            engine.say(f"The detected letter is {letter}")
            engine.runAndWait()
    except Exception as e:
        st.error("Speech engine failed.")
        st.exception(e)

# ‚úÖ Sidebar - Source Configuration
st.sidebar.header("Source Configuration")
source_radio = st.sidebar.radio("Select Source", settings.SOURCES_LIST)

# ‚úÖ IMAGE MODE
if source_radio == settings.IMAGE:
    source_img = st.sidebar.file_uploader("Choose an image...", type=["jpg", "jpeg", "png", "bmp", "webp"])
    col1, col2 = st.columns(2)

    with col1:
        try:
            if source_img is None:
                default_image_path = str(settings.DEFAULT_IMAGE)
                st.image(default_image_path, caption="Default Image", use_container_width=True)
            else:
                uploaded_image = PIL.Image.open(source_img)
                st.image(uploaded_image, caption="Uploaded Image", use_container_width=True)
        except Exception as ex:
            st.error("‚ö†Ô∏è Error while opening the image.")
            st.exception(ex)

    with col2:
        if source_img is None:
            default_detected_image_path = str(settings.DEFAULT_DETECT_IMAGE)
            st.image(default_detected_image_path, caption='Detected Output', use_container_width=True)
        else:
            if st.sidebar.button('üîç Detect Signs in Image', key="detect_image"):
                try:
                    results = model.predict(uploaded_image, conf=confidence)
                    boxes = results[0].boxes
                    detected_img = results[0].plot()[:, :, ::-1]
                    st.image(detected_img, caption='Detected Image', use_container_width=True)

                    detections = boxes.data.cpu().numpy()
                    if len(detections) > 0:
                        class_id = int(detections[0][5])
                        letter = helper.CLASS_NAMES.get(class_id, '?')
                        st.success(f"Detected Letter: {letter}")
                        st.session_state["last_detected_letter"] = letter

                    with st.expander("üìã Detection Results"):
                        for box in boxes:
                            st.write(box.data)
                except Exception as ex:
                    st.error("‚ö†Ô∏è Detection failed.")
                    st.exception(ex)

            if "last_detected_letter" in st.session_state:
                if st.button("üîä Speak Detected Letter", key="speak_image"):
                    speak_detected_letter()

# ‚úÖ VIDEO MODE
elif source_radio == settings.VIDEO:
    uploaded_video = st.sidebar.file_uploader("Upload your video...", type=["mp4", "avi", "mov", "mkv"], key="video_upload")

    if uploaded_video:
        with open("temp_uploaded_video.mp4", "wb") as f:
            f.write(uploaded_video.read())

        st.video("temp_uploaded_video.mp4")

        if st.sidebar.button("‚ñ∂Ô∏è Detect Signs in Uploaded Video", key="detect_uploaded_video"):
            try:
                vid_cap = cv2.VideoCapture("temp_uploaded_video.mp4")
                st_frame = st.empty()
                while vid_cap.isOpened():
                    success, image = vid_cap.read()
                    if success:
                        helper._display_detected_frames(confidence, model, st_frame, image)
                    else:
                        vid_cap.release()
                        break
            except Exception as e:
                st.sidebar.error("Error processing uploaded video.")
                st.exception(e)
    else:
        helper.play_stored_video(confidence, model)

# ‚úÖ WEBCAM MODE
elif source_radio == settings.WEBCAM:
    helper.play_webcam(confidence, model)

# ‚ùå Fallback
else:
    st.error("Please select a valid source from the sidebar!")
